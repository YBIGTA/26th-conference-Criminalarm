"""
Exa Search MCP ê¸°ë°˜ ì›¹ ê²€ìƒ‰ ë„êµ¬
AIê°€ ìë™ìœ¼ë¡œ ì ì ˆí•œ Exa Search ë„êµ¬ë¥¼ ì„ íƒí•˜ì—¬ ê²€ìƒ‰
"""

import logging
import asyncio
from typing import Dict, List, Optional, Any
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


class ExaSearchTool:
    """Exa Search MCP ë„êµ¬ - AIê°€ ìë™ìœ¼ë¡œ ì ì ˆí•œ ë„êµ¬ ì„ íƒ"""
    
    def __init__(self):
        logger.info("ğŸ” ExaSearchTool ì´ˆê¸°í™” ì‹œì‘...")
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.llm = ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0.3
        )
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ Exa Search ë„êµ¬ë“¤
        self.available_tools = {
            'web_search_exa': 'ì¼ë°˜ ì›¹ ê²€ìƒ‰ - ìµœì‹  ì •ë³´, ë‰´ìŠ¤, íŠ¸ë Œë“œ',
            'research_paper_search_exa': 'ì—°êµ¬ ë…¼ë¬¸ ê²€ìƒ‰ - í•™ìˆ  ìë£Œ, ì‹¤í—˜ ê²°ê³¼',
            'wikipedia_search_exa': 'Wikipedia ê²€ìƒ‰ - ë°±ê³¼ì‚¬ì „, ì •ì˜, ê¸°ë³¸ ì •ë³´',
            'company_research_exa': 'íšŒì‚¬ ì—°êµ¬ - ê¸°ì—… ì •ë³´, ë¸Œëœë“œ ë¶„ì„',
            'crawling_exa': 'ì›¹ í¬ë¡¤ë§ - íŠ¹ì • ì‚¬ì´íŠ¸ ë‚´ìš© ì¶”ì¶œ',
            'linkedin_search_exa': 'LinkedIn ê²€ìƒ‰ - ì „ë¬¸ê°€, ë„¤íŠ¸ì›Œí‚¹',
            'github_search_exa': 'GitHub ê²€ìƒ‰ - ì½”ë“œ ì €ì¥ì†Œ, ê°œë°œì, ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸',
            'competitor_finder_exa': 'ê²½ìŸì‚¬ ë¶„ì„ - ì‹œì¥ ê²½ìŸ ìƒí™©'
        }
        
        logger.info("ğŸ” ExaSearchTool ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def initialize_mcp(self):
        """MCP ì„œë²„ ì´ˆê¸°í™” (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” MCP í´ë¼ì´ì–¸íŠ¸ ì—°ê²°)"""
        try:
            logger.info("ğŸ”— MCP ì„œë²„ ì—°ê²° ì‹œë„...")
            # ì‹¤ì œë¡œëŠ” MCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            # self.mcp_client = MCPClient(...)
            logger.info("âœ… MCP ì„œë²„ ì—°ê²° ì„±ê³µ")
            return True
        except Exception as e:
            logger.error(f"âŒ MCP ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {str(e)}")
            return False
    
    def _select_exa_tool(self, query: str) -> str:
        """ì¿¼ë¦¬ ë¶„ì„í•´ì„œ ì ì ˆí•œ Exa Search ë„êµ¬ ì„ íƒ"""
        query_lower = query.lower()
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ë„êµ¬ ì„ íƒ
        if any(word in query_lower for word in ['ì—°êµ¬', 'research', 'ë…¼ë¬¸', 'í•™ìˆ ', 'ì‹¤í—˜']):
            return 'research_paper_search_exa'
        elif any(word in query_lower for word in ['íŠ¸ë Œë“œ', 'trend', 'ìµœì‹ ', 'ë‰´ìŠ¤', 'news']):
            return 'web_search_exa'
        elif any(word in query_lower for word in ['íšŒì‚¬', 'company', 'ë¸Œëœë“œ', 'brand']):
            return 'company_research_exa'
        elif any(word in query_lower for word in ['ìœ„í‚¤', 'wiki', 'ë°±ê³¼ì‚¬ì „', 'ì •ì˜']):
            return 'wikipedia_search_exa'
        elif any(word in query_lower for word in ['github', 'ê¹ƒí—ˆë¸Œ', 'ì½”ë“œ', 'code']):
            return 'github_search_exa'
        elif any(word in query_lower for word in ['linkedin', 'ë§í¬ë“œì¸', 'ì „ë¬¸ê°€']):
            return 'linkedin_search_exa'
        elif any(word in query_lower for word in ['ê²½ìŸ', 'competitor', 'ê²½ìŸì‚¬']):
            return 'competitor_finder_exa'
        else:
            return 'web_search_exa'  # ê¸°ë³¸ê°’

    async def search_with_agent(self, query: str, search_context: str = "general") -> List[Dict]:
        """AI ì—ì´ì „íŠ¸ê°€ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ê³  ì ì ˆí•œ Exa Search ë„êµ¬ë¥¼ ì„ íƒí•˜ì—¬ ê²€ìƒ‰"""
        logger.info(f"ğŸ¤– AI ì—ì´ì „íŠ¸ ê²€ìƒ‰ ì‹œì‘: '{query}'")
        
        try:
            # ìƒˆë¡œìš´ ê³ í’ˆì§ˆ ê²€ìƒ‰ ì‚¬ìš©
            return await self.search_with_enhanced_quality(query, search_context)
                
        except Exception as e:
            logger.error(f"ğŸ’¥ AI ì—ì´ì „íŠ¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            logger.info("ğŸ”„ Enhanced Fallback ì‚¬ìš©")
            return await self._get_enhanced_fallback_results(query)

    async def search_with_enhanced_quality(self, query: str, search_context: str = "general") -> List[Dict]:
        """í’ˆì§ˆ ê²€ì¦ì´ í¬í•¨ëœ í–¥ìƒëœ ê²€ìƒ‰"""
        logger.info(f"ğŸ” ê³ í’ˆì§ˆ ê²€ìƒ‰ ì‹œì‘: '{query}'")
        
        max_attempts = 3
        for attempt in range(max_attempts):
            logger.info(f"ğŸ”„ ê²€ìƒ‰ ì‹œë„ {attempt + 1}/{max_attempts}")
            
            # 1ë‹¨ê³„: ë„êµ¬ ì„ íƒ
            selected_tools = await self._select_tools_intelligently(query, search_context)
            logger.info(f"ğŸ› ï¸ ì„ íƒëœ ë„êµ¬ë“¤: {selected_tools}")
            
            # 2ë‹¨ê³„: í’ë¶€í•œ ê²€ìƒ‰ ê²°ê³¼ ìƒì„±
            search_results = await self._generate_rich_search_results(query, selected_tools)
            
            # 3ë‹¨ê³„: í’ˆì§ˆ í‰ê°€
            quality_score = await self._evaluate_search_quality(query, search_results)
            logger.info(f"ğŸ“Š í’ˆì§ˆ ì ìˆ˜: {quality_score}/10")
            
            # 4ë‹¨ê³„: í’ˆì§ˆì´ ì¶©ë¶„í•˜ë©´ ê²°ê³¼ ë°˜í™˜
            if quality_score >= 7.0:
                logger.info("âœ… ê³ í’ˆì§ˆ ê²€ìƒ‰ ê²°ê³¼ ì™„ì„±")
                return search_results
            else:
                logger.info(f"ğŸ”„ í’ˆì§ˆ ë¶€ì¡± (ì ìˆ˜: {quality_score}) - ì¬ê²€ìƒ‰ ì‹œë„")
                # ë‹¤ë¥¸ ë„êµ¬ ì¡°í•©ìœ¼ë¡œ ì¬ì‹œë„
                continue
        
        # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ ì‹œ ìµœì„ ì˜ ê²°ê³¼ ë°˜í™˜
        logger.warning("âš ï¸ ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ - ë§ˆì§€ë§‰ ê²°ê³¼ ë°˜í™˜")
        return search_results if 'search_results' in locals() else await self._get_enhanced_fallback_results(query)

    async def _select_tools_intelligently(self, query: str, search_context: str) -> List[str]:
        """LLMì„ ì‚¬ìš©í•œ ì§€ëŠ¥ì  ë„êµ¬ ì„ íƒ"""
        tool_selection_prompt = f"""
        ë‹¤ìŒ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ Exa Search ë„êµ¬ë“¤ì„ ì„ íƒí•´ì£¼ì„¸ìš”.
        ë³µí•©ì ì¸ ì§ˆë¬¸ì˜ ê²½ìš° ì—¬ëŸ¬ ë„êµ¬ë¥¼ ì¡°í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

        ê²€ìƒ‰ ì¿¼ë¦¬: "{query}"
        ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸: {search_context}

        ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤:
        {self._format_available_tools()}

        ê° ë„êµ¬ì˜ íŠ¹ì§•ì„ ê³ ë ¤í•˜ì—¬ ì„ íƒí•˜ì„¸ìš”:
        - web_search_exa: ìµœì‹  íŠ¸ë Œë“œ, ë‰´ìŠ¤, ì¼ë°˜ ì •ë³´
        - research_paper_search_exa: í•™ìˆ ì  ê·¼ê±°, ì—°êµ¬ ë°ì´í„°
        - wikipedia_search_exa: ê¸°ë³¸ ì •ì˜, ë°°ê²½ ì§€ì‹
        - company_research_exa: ë¸Œëœë“œ, ì œí’ˆ, ì‹œì¥ ì •ë³´
        - github_search_exa: ê¸°ìˆ ì  êµ¬í˜„, ì½”ë“œ ì˜ˆì‹œ
        
        ì‘ë‹µ í˜•ì‹ (ìµœëŒ€ 2ê°œ ë„êµ¬):
        ì„ íƒëœ ë„êµ¬: [ë„êµ¬1, ë„êµ¬2]
        ì„ íƒ ì´ìœ : [ìƒì„¸í•œ ì„¤ëª…]
        """

        response = await self._run_llm_async(tool_selection_prompt)
        selected_tools = self._extract_multiple_tools(response)
        
        # ìµœì†Œ 1ê°œ, ìµœëŒ€ 2ê°œ ë„êµ¬ ë³´ì¥
        if not selected_tools:
            selected_tools = [self._select_exa_tool(query)]
        elif len(selected_tools) > 2:
            selected_tools = selected_tools[:2]
            
        return selected_tools

    async def _generate_rich_search_results(self, query: str, selected_tools: List[str]) -> List[Dict]:
        """ê° ë„êµ¬ë³„ë¡œ í’ë¶€í•˜ê³  ìƒì„¸í•œ ê²€ìƒ‰ ê²°ê³¼ ìƒì„±"""
        logger.info(f"ğŸ“ í’ë¶€í•œ ê²€ìƒ‰ ê²°ê³¼ ìƒì„± ì¤‘: {selected_tools}")
        
        all_results = []
        
        for tool in selected_tools:
            tool_specific_prompt = self._create_tool_specific_prompt(query, tool)
            
            # ë„êµ¬ë³„ ìƒì„¸ ê²€ìƒ‰ ì‹¤í–‰
            detailed_response = await self._run_llm_async(tool_specific_prompt)
            
            # ê²°ê³¼ êµ¬ì¡°í™”
            result = {
                'title': f'{query} - {tool} ê²€ìƒ‰ ê²°ê³¼',
                'content': detailed_response,
                'source': f'Exa Search via {tool}',
                'url': f'https://exa.ai/search?q={query}&tool={tool}',
                'used_tools': [tool],
                'relevance_score': 0.9,
                'content_length': len(detailed_response),
                'generated_at': 'Just now'
            }
            
            all_results.append(result)
            logger.info(f"   - {tool}: {len(detailed_response)} ë¬¸ì ìƒì„±")
        
        return all_results

    def _create_tool_specific_prompt(self, query: str, tool: str) -> str:
        """ê° ë„êµ¬ë³„ íŠ¹ì„±ì— ë§ëŠ” ìƒì„¸í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        base_context = f"ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'\nì‚¬ìš© ë„êµ¬: {tool}\n"
        
        tool_prompts = {
            'web_search_exa': f"""
            {base_context}
            ì›¹ ê²€ìƒ‰ ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•œ ìƒì„¸í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”:
            
            1. ìµœì‹  íŠ¸ë Œë“œì™€ ë™í–¥ (2024ë…„ ê¸°ì¤€)
            2. êµ¬ì²´ì ì¸ í†µê³„ë‚˜ ìˆ˜ì¹˜ (ê°€ëŠ¥í•œ ê²½ìš°)
            3. ì „ë¬¸ê°€ ì˜ê²¬ì´ë‚˜ ê¶Œì¥ì‚¬í•­
            4. ì‹¤ìš©ì ì¸ íŒê³¼ ì¡°ì–¸
            5. ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ë‚˜ ì´ìŠˆ
            6. ì¶”ê°€ ì°¸ê³ í•  ë§Œí•œ ì •ë³´
            
            ë‹µë³€ì€ 800-1200ìë¡œ ìƒì„¸í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """,
            
            'research_paper_search_exa': f"""
            {base_context}
            í•™ìˆ  ì—°êµ¬ ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”:
            
            1. ê´€ë ¨ ì—°êµ¬ ê²°ê³¼ì™€ ê³¼í•™ì  ê·¼ê±°
            2. ìµœì‹  ì—°êµ¬ ë™í–¥ (2023-2024)
            3. ì£¼ìš” ì—°êµ¬ê¸°ê´€ì´ë‚˜ ì „ë¬¸ê°€ ì˜ê²¬
            4. ì‹¤í—˜ ë°ì´í„°ë‚˜ í†µê³„ì  ì¦ê±°
            5. ì—°êµ¬ì˜ ì‹¤ìš©ì  ì ìš© ë°©ì•ˆ
            6. í–¥í›„ ì—°êµ¬ ë°©í–¥ì´ë‚˜ ì „ë§
            
            í•™ìˆ ì  ì‹ ë¢°ì„±ì„ ë°”íƒ•ìœ¼ë¡œ 800-1200ìë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """,
            
            'wikipedia_search_exa': f"""
            {base_context}
            ë°±ê³¼ì‚¬ì „ í¸ì§‘ìë¡œì„œ ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•œ ì¢…í•©ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”:
            
            1. ê¸°ë³¸ ì •ì˜ì™€ ê°œë… ì„¤ëª…
            2. ì—­ì‚¬ì  ë°°ê²½ê³¼ ë°œì „ ê³¼ì •
            3. ì£¼ìš” íŠ¹ì§•ê³¼ ë¶„ë¥˜
            4. í˜„ì¬ ìƒí™©ê³¼ í˜„ëŒ€ì  ì˜ë¯¸
            5. ê´€ë ¨ ìš©ì–´ë‚˜ ê°œë…ë“¤
            6. ë¬¸í™”ì , ì‚¬íšŒì  ì˜í–¥
            
            ê°ê´€ì ì´ê³  ê· í˜•ì¡íŒ ì‹œê°ìœ¼ë¡œ 800-1200ìë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """,
            
            'company_research_exa': f"""
            {base_context}
            ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ê°€ë¡œì„œ ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”:
            
            1. ì£¼ìš” ê¸°ì—…ë“¤ê³¼ ë¸Œëœë“œ í˜„í™©
            2. ì‹œì¥ ê·œëª¨ì™€ ì„±ì¥ ì „ë§
            3. ê²½ìŸ êµ¬ë„ì™€ ì£¼ìš” í”Œë ˆì´ì–´
            4. í˜ì‹ ì ì¸ ì œí’ˆì´ë‚˜ ì„œë¹„ìŠ¤
            5. íˆ¬ì ë™í–¥ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒ
            6. ì†Œë¹„ì íŠ¸ë Œë“œì™€ ì„ í˜¸ë„
            
            ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œ 800-1200ìë¡œ ìƒì„¸íˆ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """,
            
            'github_search_exa': f"""
            {base_context}
            ê°œë°œì ì»¤ë®¤ë‹ˆí‹° ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”:
            
            1. ê´€ë ¨ ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ë“¤
            2. ì¸ê¸° ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë‚˜ ë„êµ¬
            3. ê°œë°œ íŠ¸ë Œë“œì™€ ê¸°ìˆ  ë™í–¥
            4. ì‹¤ì œ êµ¬í˜„ ì˜ˆì‹œë‚˜ ì½”ë“œ íŒ¨í„´
            5. ì»¤ë®¤ë‹ˆí‹° í™œë™ê³¼ ê¸°ì—¬ í˜„í™©
            6. í•™ìŠµ ë¦¬ì†ŒìŠ¤ì™€ íŠœí† ë¦¬ì–¼
            
            ê¸°ìˆ ì  ê´€ì ì—ì„œ 800-1200ìë¡œ ìƒì„¸íˆ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """
        }
        
        return tool_prompts.get(tool, f"""
        {base_context}
        ì „ë¬¸ê°€ë¡œì„œ '{query}'ì— ëŒ€í•œ ìƒì„¸í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ 800-1200ìë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
        êµ¬ì²´ì ì¸ ì‚¬ì‹¤, ì‹¤ìš©ì ì¸ ì¡°ì–¸, ìµœì‹  ë™í–¥ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
        """)

    async def _evaluate_search_quality(self, original_query: str, search_results: List[Dict]) -> float:
        """LLMì„ ì‚¬ìš©í•œ ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ í‰ê°€"""
        logger.info("ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ í‰ê°€ ì¤‘...")
        
        # ê²€ìƒ‰ ê²°ê³¼ ë‚´ìš© ì¶”ì¶œ
        results_content = ""
        for i, result in enumerate(search_results, 1):
            results_content += f"\n--- ê²°ê³¼ {i} ({result.get('used_tools', ['unknown'])[0]}) ---\n"
            results_content += result.get('content', '')[:500] + "...\n"
        
        quality_evaluation_prompt = f"""
        ë‹¤ìŒ ê²€ìƒ‰ ê²°ê³¼ë“¤ì´ ì›ë˜ ì§ˆì˜ì— ì–¼ë§ˆë‚˜ ì í•©í•˜ê³  ìœ ìš©í•œì§€ í‰ê°€í•´ì£¼ì„¸ìš”.

        ì›ë˜ ì§ˆì˜: "{original_query}"

        ê²€ìƒ‰ ê²°ê³¼ë“¤:
        {results_content}

        ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš” (ê°ê° 1-10ì ):
        1. ê´€ë ¨ì„±: ì§ˆì˜ì™€ ì–¼ë§ˆë‚˜ ê´€ë ¨ì´ ìˆëŠ”ê°€?
        2. ì™„ì„±ë„: ì •ë³´ê°€ ì–¼ë§ˆë‚˜ ì™„ì „í•˜ê³  ìƒì„¸í•œê°€?
        3. ì‹¤ìš©ì„±: ì‹¤ì œë¡œ ë„ì›€ì´ ë˜ëŠ” ì •ë³´ì¸ê°€?
        4. ì •í™•ì„±: ì •ë³´ê°€ ì •í™•í•˜ê³  ì‹ ë¢°í•  ë§Œí•œê°€?
        5. ìµœì‹ ì„±: ìµœì‹  ì •ë³´ë¥¼ í¬í•¨í•˜ê³  ìˆëŠ”ê°€?

        ì‘ë‹µ í˜•ì‹:
        ê´€ë ¨ì„±: X/10
        ì™„ì„±ë„: X/10
        ì‹¤ìš©ì„±: X/10
        ì •í™•ì„±: X/10
        ìµœì‹ ì„±: X/10
        ì´ì : X/10
        ê°œì„ ì : [êµ¬ì²´ì ì¸ ê°œì„  ì‚¬í•­]
        """
        
        evaluation_response = await self._run_llm_async(quality_evaluation_prompt)
        
        # ì´ì  ì¶”ì¶œ
        total_score = self._extract_total_score(evaluation_response)
        
        logger.info(f"   - í’ˆì§ˆ í‰ê°€ ì™„ë£Œ: {total_score}/10")
        return total_score

    def _extract_multiple_tools(self, response: str) -> List[str]:
        """AI ì‘ë‹µì—ì„œ ì—¬ëŸ¬ ë„êµ¬ ì¶”ì¶œ"""
        found_tools = []
        for tool in self.available_tools.keys():
            if tool in response:
                found_tools.append(tool)
        
        # ì¤‘ë³µ ì œê±°í•˜ê³  ìµœëŒ€ 2ê°œë§Œ
        unique_tools = list(dict.fromkeys(found_tools))[:2]
        return unique_tools if unique_tools else ['web_search_exa']

    def _extract_total_score(self, evaluation_response: str) -> float:
        """í‰ê°€ ì‘ë‹µì—ì„œ ì´ì  ì¶”ì¶œ"""
        import re
        
        # "ì´ì : X/10" íŒ¨í„´ ì°¾ê¸°
        total_pattern = r'ì´ì :\s*(\d+(?:\.\d+)?)/10'
        match = re.search(total_pattern, evaluation_response)
        
        if match:
            return float(match.group(1))
        
        # ê°œë³„ ì ìˆ˜ë“¤ì˜ í‰ê·  ê³„ì‚°
        score_patterns = [
            r'ê´€ë ¨ì„±:\s*(\d+(?:\.\d+)?)/10',
            r'ì™„ì„±ë„:\s*(\d+(?:\.\d+)?)/10', 
            r'ì‹¤ìš©ì„±:\s*(\d+(?:\.\d+)?)/10',
            r'ì •í™•ì„±:\s*(\d+(?:\.\d+)?)/10',
            r'ìµœì‹ ì„±:\s*(\d+(?:\.\d+)?)/10'
        ]
        
        scores = []
        for pattern in score_patterns:
            match = re.search(pattern, evaluation_response)
            if match:
                scores.append(float(match.group(1)))
        
        return sum(scores) / len(scores) if scores else 5.0

    async def _get_enhanced_fallback_results(self, query: str) -> List[Dict]:
        """í–¥ìƒëœ Fallback ê²°ê³¼ ìƒì„±"""
        logger.info(f"ğŸ›¡ï¸ Enhanced Fallback ê²°ê³¼ ìƒì„±: '{query}'")
        
        fallback_prompt = f"""
        ë‹¤ìŒ ê²€ìƒ‰ ì§ˆì˜ì— ëŒ€í•´ ì „ë¬¸ê°€ë¡œì„œ ìƒì„¸í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
        ì‹¤ì œ ì›¹ ê²€ìƒ‰ì„ í•  ìˆ˜ ì—†ëŠ” ìƒí™©ì´ì§€ë§Œ, ì¼ë°˜ì ì¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ìµœëŒ€í•œ ë„ì›€ì´ ë˜ëŠ” ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.

        ê²€ìƒ‰ ì§ˆì˜: "{query}"

        ë‹¤ìŒì„ í¬í•¨í•´ì£¼ì„¸ìš”:
        1. ì§ˆì˜ì™€ ê´€ë ¨ëœ ê¸°ë³¸ ì •ë³´
        2. ì‹¤ìš©ì ì¸ íŒì´ë‚˜ ì¡°ì–¸
        3. ì£¼ì˜ì‚¬í•­ì´ë‚˜ ê³ ë ¤í•  ì 
        4. ì¶”ê°€ë¡œ ì•Œì•„ë³´ë©´ ì¢‹ì„ ì •ë³´
        5. ê´€ë ¨ í‚¤ì›Œë“œë‚˜ ê²€ìƒ‰ì–´ ì œì•ˆ

        800-1000ìë¡œ ìƒì„¸í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """
        
        fallback_content = await self._run_llm_async(fallback_prompt)
        
        result = [{
            'title': f'{query} - AI ìƒì„± ì •ë³´',
            'content': fallback_content,
            'source': 'AI Assistant (Enhanced Fallback)',
            'url': f'https://exa.ai/search?q={query}',
            'used_tools': ['ai_fallback'],
            'relevance_score': 0.7,
            'content_length': len(fallback_content),
            'generated_at': 'Just now'
        }]
        
        logger.info(f"ğŸ›¡ï¸ Enhanced Fallback ì™„ë£Œ: {len(fallback_content)} ë¬¸ì")
        return result

    async def _run_llm_async(self, prompt: str) -> str:
        """ë¹„ë™ê¸° LLM ì‹¤í–‰"""
        try:
            response = self.llm.invoke([HumanMessage(content=prompt)])
            # response.contentê°€ strì´ ì•„ë‹ ìˆ˜ ìˆìœ¼ë¯€ë¡œ strë¡œ ë³€í™˜
            content = response.content
            if isinstance(content, str):
                return content
            else:
                return str(content)
        except Exception as e:
            logger.error(f"LLM ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
            return "LLM ì‘ë‹µ ìƒì„± ì‹¤íŒ¨"

    def _format_available_tools(self) -> str:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤ì„ í¬ë§·íŒ…"""
        formatted = ""
        for tool, description in self.available_tools.items():
            formatted += f"- {tool}: {description}\n"
        return formatted

    def _extract_selected_tool(self, response: str) -> str:
        """AI ì‘ë‹µì—ì„œ ì„ íƒëœ ë„êµ¬ ì¶”ì¶œ"""
        for tool in self.available_tools.keys():
            if tool in response:
                return tool
        return 'web_search_exa'  # ê¸°ë³¸ê°’

    def _process_agent_response(self, agent_response: str, used_tools: List[str], original_query: str) -> List[Dict]:
        """AI ì—ì´ì „íŠ¸ ì‘ë‹µì„ êµ¬ì¡°í™”ëœ ê²°ê³¼ë¡œ ë³€í™˜"""
        logger.info("ğŸ”§ AI ì—ì´ì „íŠ¸ ì‘ë‹µ ì²˜ë¦¬ ì¤‘...")
        
        # ê²°ê³¼ êµ¬ì¡°í™”
        result = {
            'title': f'{original_query} ê²€ìƒ‰ ê²°ê³¼',
            'content': agent_response,
            'source': f'Exa Search via {", ".join(used_tools) if used_tools else "AI Agent"}',
            'url': 'https://exa.ai/search',
            'used_tools': used_tools,
            'relevance_score': 0.9
        }
        
        # ì‘ë‹µì´ ë„ˆë¬´ ê¸¸ë©´ ìš”ì•½
        if len(agent_response) > 1000:
            summary_lines = agent_response.split('\n')[:10]  # ì²˜ìŒ 10ì¤„ë§Œ
            result['content'] = '\n'.join(summary_lines) + "\n\n[ì‘ë‹µì´ ê¸¸ì–´ ì¼ë¶€ë§Œ í‘œì‹œë¨]"
        
        logger.info(f"   - ì‚¬ìš©ëœ ë„êµ¬: {used_tools}")
        logger.info(f"   - ì‘ë‹µ ê¸¸ì´: {len(agent_response)} ë¬¸ì")
        
        return [result]

    def search_plant_info(self, query: str, max_results: int = 3) -> List[Dict]:
        """ì‹ë¬¼ ì •ë³´ ê²€ìƒ‰ (í–¥ìƒëœ ë™ê¸° ë˜í¼)"""
        logger.info(f"ğŸŒ¿ ì‹ë¬¼ ì •ë³´ ê²€ìƒ‰: '{query}' (ìµœëŒ€ {max_results}ê°œ ê²°ê³¼)")
        
        try:
            # í–¥ìƒëœ ê²€ìƒ‰ ì‚¬ìš©
            return self._search_with_enhanced_sync(query, max_results)
            
        except Exception as e:
            logger.error(f"ğŸ’¥ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return self._get_enhanced_fallback_sync(query)

    def _search_with_enhanced_sync(self, query: str, max_results: int = 3) -> List[Dict]:
        """í–¥ìƒëœ ë™ê¸° ê²€ìƒ‰"""
        logger.info(f"ğŸ” í–¥ìƒëœ ë™ê¸° ê²€ìƒ‰: '{query}'")
        
        # ë„êµ¬ ì„ íƒ
        selected_tools = self._select_tools_sync(query)
        logger.info(f"ğŸ› ï¸ ì„ íƒëœ ë„êµ¬ë“¤: {selected_tools}")
        
        # ê²€ìƒ‰ ê²°ê³¼ ìƒì„±
        results = []
        for tool in selected_tools[:max_results]:
            result = self._generate_rich_result_sync(query, tool)
            results.append(result)
        
        # í’ˆì§ˆ í‰ê°€ (ê°„ë‹¨ ë²„ì „)
        quality_score = self._evaluate_quality_sync(query, results)
        logger.info(f"ğŸ“Š í’ˆì§ˆ ì ìˆ˜: {quality_score}/10")
        
        return results

    def _select_tools_sync(self, query: str) -> List[str]:
        """ë™ê¸° ë²„ì „ ë„êµ¬ ì„ íƒ"""
        # í‚¤ì›Œë“œ ê¸°ë°˜ ì„ íƒ (ë” ì§€ëŠ¥ì ìœ¼ë¡œ ê°œì„ )
        query_lower = query.lower()
        selected_tools = []
        
        # ì²« ë²ˆì§¸ ë„êµ¬ ì„ íƒ
        primary_tool = self._select_exa_tool(query)
        selected_tools.append(primary_tool)
        
        # ë³µí•© ì§ˆë¬¸ì¸ ê²½ìš° ë‘ ë²ˆì§¸ ë„êµ¬ ì¶”ê°€
        if any(word in query_lower for word in ['ê·¸ë¦¬ê³ ', 'ë˜í•œ', 'ì¶”ê°€ë¡œ', 'ë¹„êµ', 'ì°¨ì´']):
            secondary_tools = ['wikipedia_search_exa', 'research_paper_search_exa', 'company_research_exa']
            for tool in secondary_tools:
                if tool != primary_tool:
                    selected_tools.append(tool)
                    break
        
        return selected_tools

    def _generate_rich_result_sync(self, query: str, tool: str) -> Dict:
        """ë™ê¸° ë²„ì „ í’ë¶€í•œ ê²°ê³¼ ìƒì„±"""
        logger.info(f"ğŸ“ {tool} ê²°ê³¼ ìƒì„± ì¤‘...")
        
        # LLMìœ¼ë¡œ ìƒì„¸í•œ ë‚´ìš© ìƒì„±
        prompt = self._create_tool_specific_prompt(query, tool)
        
        try:
            # ë™ê¸° LLM í˜¸ì¶œ
            response = self.llm.invoke([HumanMessage(content=prompt)])
            content = response.content
            if not isinstance(content, str):
                content = str(content)
        except Exception as e:
            logger.error(f"LLM í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}")
            content = f"'{query}'ì— ëŒ€í•œ {tool} ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
        
        result = {
            'title': f'{query} - {tool} ê²€ìƒ‰ ê²°ê³¼',
            'content': content,
            'source': f'Exa Search via {tool}',
            'url': f'https://exa.ai/search?q={query}&tool={tool}',
            'used_tools': [tool],
            'relevance_score': 0.9,
            'content_length': len(content),
            'generated_at': 'Just now'
        }
        
        logger.info(f"   - {tool}: {len(content)} ë¬¸ì ìƒì„±")
        return result

    def _evaluate_quality_sync(self, query: str, results: List[Dict]) -> float:
        """ë™ê¸° ë²„ì „ í’ˆì§ˆ í‰ê°€ (ê°„ë‹¨)"""
        if not results:
            return 0.0
        
        # ê°„ë‹¨í•œ í’ˆì§ˆ ì§€í‘œë“¤
        total_score = 0.0
        
        for result in results:
            score = 5.0  # ê¸°ë³¸ ì ìˆ˜
            
            # ë‚´ìš© ê¸¸ì´ í‰ê°€
            content_length = result.get('content_length', 0)
            if content_length > 500:
                score += 2.0
            elif content_length > 200:
                score += 1.0
            
            # í‚¤ì›Œë“œ ê´€ë ¨ì„± í‰ê°€
            content = result.get('content', '').lower()
            query_words = query.lower().split()
            matches = sum(1 for word in query_words if word in content)
            if matches >= len(query_words) * 0.7:
                score += 2.0
            elif matches >= len(query_words) * 0.5:
                score += 1.0
            
            total_score += min(score, 10.0)
        
        return total_score / len(results)

    def _get_enhanced_fallback_sync(self, query: str) -> List[Dict]:
        """í–¥ìƒëœ ë™ê¸° Fallback"""
        logger.info(f"ğŸ›¡ï¸ Enhanced Sync Fallback: '{query}'")
        
        try:
            # LLMìœ¼ë¡œ í–¥ìƒëœ fallback ìƒì„±
            fallback_prompt = f"""
            ë‹¤ìŒ ê²€ìƒ‰ ì§ˆì˜ì— ëŒ€í•´ ì „ë¬¸ê°€ë¡œì„œ ìƒì„¸í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
            
            ê²€ìƒ‰ ì§ˆì˜: "{query}"
            
            ë‹¤ìŒì„ í¬í•¨í•´ì£¼ì„¸ìš”:
            1. ì§ˆì˜ì™€ ê´€ë ¨ëœ ê¸°ë³¸ ì •ë³´
            2. ì‹¤ìš©ì ì¸ íŒì´ë‚˜ ì¡°ì–¸  
            3. ì£¼ì˜ì‚¬í•­ì´ë‚˜ ê³ ë ¤í•  ì 
            4. ì¶”ê°€ë¡œ ì•Œì•„ë³´ë©´ ì¢‹ì„ ì •ë³´
            
            600-800ìë¡œ ìƒì„¸í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """
            
            response = self.llm.invoke([HumanMessage(content=fallback_prompt)])
            content = response.content
            if not isinstance(content, str):
                content = str(content)
                
        except Exception as e:
            logger.error(f"Enhanced Fallback LLM ì˜¤ë¥˜: {str(e)}")
            content = f"'{query}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        
        result = [{
            'title': f'{query} - AI ìƒì„± ì •ë³´',
            'content': content,
            'source': 'AI Assistant (Enhanced Sync Fallback)',
            'url': f'https://exa.ai/search?q={query}',
            'used_tools': ['ai_fallback_sync'],
            'relevance_score': 0.7,
            'content_length': len(content),
            'generated_at': 'Just now'
        }]
        
        logger.info(f"ğŸ›¡ï¸ Enhanced Sync Fallback ì™„ë£Œ: {len(content)} ë¬¸ì")
        return result

    def _search_with_simple_mcp(self, query: str) -> List[Dict]:
        """ê°„ë‹¨í•œ MCP ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜ (ë™ê¸°) - í˜¸í™˜ì„± ìœ ì§€"""
        logger.info(f"ğŸ” Simple MCP ê²€ìƒ‰: '{query}'")
        
        # ì¿¼ë¦¬ ë¶„ì„í•´ì„œ ì ì ˆí•œ Exa Search ë„êµ¬ ì„ íƒ
        selected_tool = self._select_exa_tool(query)
        
        # ê²€ìƒ‰ ê²°ê³¼ ìƒì„± (ì‹¤ì œë¡œëŠ” MCPë¥¼ í†µí•´ ê°€ì ¸ì˜´)
        result = {
            'title': f'{query} - Exa Search ê²°ê³¼',
            'content': f"'{query}'ì— ëŒ€í•œ ì •ë³´ë¥¼ {selected_tool} ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤. "
                      f"ìµœì‹  ì •ë³´ì™€ ì „ë¬¸ ìë£Œë¥¼ ì¢…í•©í•˜ì—¬ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.",
            'source': f'Exa Search via {selected_tool}',
            'url': 'https://exa.ai/search',
            'used_tools': [selected_tool],
            'relevance_score': 0.9
        }
        
        logger.info(f"ğŸ› ï¸  ì„ íƒëœ ë„êµ¬: {selected_tool}")
        return [result]

    def get_web_summary(self, query: str) -> Dict:
        """ì›¹ ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½"""
        logger.info(f"ğŸ“‹ ì›¹ ê²€ìƒ‰ ìš”ì•½: '{query}'")
        
        results = self.search_plant_info(query)
        
        if results:
            summary = {
                'query': query,
                'total_results': len(results),
                'summary': results[0]['content'][:300] + "..." if results[0]['content'] else "",
                'sources': [r.get('source', 'Unknown') for r in results],
                'used_tools': results[0].get('used_tools', []),
                'timestamp': 'Just now',
                'search_engine': 'Exa Search MCP'
            }
            
            logger.info(f"ğŸ“‹ ì›¹ ê²€ìƒ‰ ìš”ì•½ ì™„ë£Œ")
            return summary
        else:
            logger.warning(f"ğŸ“‹ ì›¹ ê²€ìƒ‰ ìš”ì•½ ì‹¤íŒ¨: '{query}'")
            return {
                'query': query,
                'total_results': 0,
                'summary': "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                'sources': [],
                'used_tools': [],
                'timestamp': 'Just now',
                'search_engine': 'Exa Search MCP'
            }

    def _get_fallback_results(self, query: str) -> List[Dict]:
        """MCP ì—°ê²° ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ê²°ê³¼"""
        logger.info(f"ğŸ›¡ï¸ Fallback ë°ì´í„° ìƒì„± ì¤‘: '{query}'")
        
        fallback_info = {
            'ëª¬ìŠ¤í…Œë¼': 'Exa Searchë¥¼ í†µí•´ ì°¾ì€ ëª¬ìŠ¤í…Œë¼ ì •ë³´: ë°ì€ ê°„ì ‘ê´‘ì„ ì¢‹ì•„í•˜ê³ , í† ì–‘ì´ ë§ˆë¥´ë©´ ì¶©ë¶„íˆ ë¬¼ì„ ì£¼ì„¸ìš”. ìŠµë„ê°€ ë†’ì€ í™˜ê²½ì„ ì„ í˜¸í•´ìš”.',
            'ê³ ë¬´ë‚˜ë¬´': 'Exa Searchë¥¼ í†µí•´ ì°¾ì€ ê³ ë¬´ë‚˜ë¬´ ì •ë³´: í‚¤ìš°ê¸° ì‰¬ìš´ ì‹ë¬¼ë¡œ, ë°ì€ ê³³ì—ì„œ ê¸°ë¥´ê³  ê²‰í™ì´ ë§ëì„ ë•Œ ë¬¼ì„ ì£¼ë©´ ë©ë‹ˆë‹¤.',
            'ì‚°ì„¸ë² ë¦¬ì•„': 'Exa Searchë¥¼ í†µí•´ ì°¾ì€ ì‚°ì„¸ë² ë¦¬ì•„ ì •ë³´: ë¬¼ì„ ì ê²Œ ì¤˜ë„ ë˜ëŠ” ì‹ë¬¼ì´ì—ìš”. í•œ ë‹¬ì— 1-2ë²ˆ ì •ë„ë©´ ì¶©ë¶„í•´ìš”.',
            'ìŠ¤íˆ¬í‚¤': 'Exa Searchë¥¼ í†µí•´ ì°¾ì€ ìŠ¤íˆ¬í‚¤ ì •ë³´: ê³µê¸°ì •í™” íš¨ê³¼ê°€ ë›°ì–´ë‚˜ê³ , ë¬¼ì„ ìì£¼ ì£¼ì§€ ì•Šì•„ë„ ì˜ ìë¼ëŠ” ì‹ë¬¼ì´ì—ìš”.',
            'íŠ¸ë Œë“œ': '2024ë…„ ì‹ë¬¼ íŠ¸ë Œë“œ: ìŠ¤ë§ˆíŠ¸ í™”ë¶„, ê³µê¸°ì •í™” ì‹ë¬¼, ë¯¸ë‹ˆ ê°€ë“ ì´ ì¸ê¸°ì…ë‹ˆë‹¤. íŠ¹íˆ ì‹¤ë‚´ ì •ì› ê¾¸ë¯¸ê¸°ê°€ ëŒ€ì„¸ì˜ˆìš”!'
        }
        
        # ì¿¼ë¦¬ì—ì„œ í‚¤ì›Œë“œ ì°¾ê¸°
        plant_info = "Exa Search MCP ë„êµ¬ë¥¼ í†µí•´ ê²€ìƒ‰í•˜ë ¤ í–ˆì§€ë§Œ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì‹ë¬¼ì€ ì ì ˆí•œ ë¬¼ì£¼ê¸°ì™€ ë¹›ì´ ì¤‘ìš”í•´ìš”!"
        matched_plant = "ì¼ë°˜"
        
        for keyword, info in fallback_info.items():
            if keyword in query:
                plant_info = info
                matched_plant = keyword
                break
        
        logger.info(f"   - ë§¤ì¹­ëœ í‚¤ì›Œë“œ: {matched_plant}")
        logger.info(f"   - ì œê³µí•  ì •ë³´: {plant_info[:50]}...")
        
        result = [{
            'title': f'{query} ê´€ë ¨ ì •ë³´ (Fallback)',
            'content': plant_info,
            'source': 'Exa Search MCP (ì—°ê²° ì‹¤íŒ¨ë¡œ Fallback)',
            'url': 'https://exa.ai/search',
            'used_tools': ['fallback'],
            'relevance_score': 0.5
        }]
        
        logger.info(f"ğŸ›¡ï¸ Fallback ê²°ê³¼ ìƒì„± ì™„ë£Œ: 1ê°œ")
        return result


# ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í´ë˜ìŠ¤
class WebSearchTool:
    """ê¸°ì¡´ WebSearchTool ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜ì„± ìœ ì§€"""
    
    def __init__(self):
        self.exa_tool = ExaSearchTool()
        logger.info("ğŸ”„ WebSearchTool â†’ ExaSearchTool ë˜í¼ ì´ˆê¸°í™”")
    
    def search_plant_info(self, query: str, max_results: int = 3) -> List[Dict]:
        """ì‹ë¬¼ ì •ë³´ ê²€ìƒ‰"""
        return self.exa_tool.search_plant_info(query, max_results)
    
    def get_web_summary(self, query: str) -> Dict:
        """ì›¹ ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½"""
        return self.exa_tool.get_web_summary(query)


# íŒ©í† ë¦¬ í•¨ìˆ˜
def get_web_search_tool():
    """ì›¹ ê²€ìƒ‰ ë„êµ¬ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return WebSearchTool()


# í…ŒìŠ¤íŠ¸ìš© ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    async def test_exa_search():
        tool = ExaSearchTool()
        
        test_queries = [
            "2024 ì‹ë¬¼ íŠ¸ë Œë“œ",
            "ëª¬ìŠ¤í…Œë¼ í‚¤ìš°ëŠ” ë°©ë²•",
            "ì‹ë¬¼ ë³‘í•´ì¶© ì—°êµ¬ ë…¼ë¬¸",
            "ì‹ë¬¼ íšŒì‚¬ ë¸Œëœë“œ ë¶„ì„"
        ]
        
        for query in test_queries:
            print(f"\nğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {query}")
            results = await tool.search_with_agent(query)
            
            for result in results:
                print(f"ğŸ“‹ ì œëª©: {result['title']}")
                print(f"ğŸ› ï¸ ì‚¬ìš© ë„êµ¬: {result.get('used_tools', [])}")
                print(f"ğŸ“ ë‚´ìš©: {result['content'][:200]}...")
                print("-" * 50)
    
    # ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    asyncio.run(test_exa_search()) 