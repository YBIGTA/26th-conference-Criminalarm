"""
LangGraph ê¸°ë°˜ Plant Orchestrator 
AI-powered Tool Orchestration with Complex Workflow
"""

from typing import Dict, List, TypedDict, Annotated, Literal, Optional
from langchain_openai import ChatOpenAI
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
import json

from tools.data_analyzer import EnvironmentDataAnalyzer
from tools.web_search_tool import WebSearchTool
from tools.dummy_rag_tool import PlantKnowledgeRAG

# OpenAI API í‚¤ ì„¤ì •
from dotenv import load_dotenv
load_dotenv()


class OrchestratorState(TypedDict):
    """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìƒíƒœ ì •ì˜"""
    messages: Annotated[List[BaseMessage], add_messages]
    query: str
    conversation_history: List[Dict]
    analysis_result: Dict
    tools_to_use: List[str]
    tool_results: Dict
    reasoning: str
    iteration_count: int
    is_complete: bool
    next_action: str


class PlantOrchestrator:
    """LangGraph ê¸°ë°˜ AI ë„êµ¬ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""
    
    def __init__(self):
        # LLM ì´ˆê¸°í™”
        self.llm = ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0.3
        )
        
        # ë„êµ¬ ì´ˆê¸°í™”
        self.env_analyzer = EnvironmentDataAnalyzer()
        self.web_search = WebSearchTool()
        self.rag_system = PlantKnowledgeRAG()
        
        # ë„êµ¬ ì„¤ëª…
        self.tool_descriptions = {
            "environment": "í™˜ê²½ ë°ì´í„° ë¶„ì„ê¸° - ì˜¨ë„, ìŠµë„, í† ì–‘ìˆ˜ë¶„, ê´‘ë„ ë“± ì‹¤ì‹œê°„ í™˜ê²½ ìƒíƒœ ë¶„ì„",
            "web_search": "Exa Search MCP ì—”ì§„ - AIê°€ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•´ì„œ ì ì ˆí•œ Exa Search ë„êµ¬ë¥¼ ì„ íƒí•˜ì—¬ ìµœì‹  ì •ë³´ ê²€ìƒ‰",
            "knowledge": "ì‹ë¬¼ ì§€ì‹ RAG - ì‹ë¬¼ ê´€ë¦¬, ì¢…ë¥˜ë³„ íŠ¹ì„±, ì „ë¬¸ ì§€ì‹ ë“± ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰"
        }
        
        # LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„±
        self.workflow = self._create_workflow()
    
    def _create_workflow(self) -> StateGraph:
        """ë³µì¡í•œ LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„±"""
        workflow = StateGraph(OrchestratorState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("initial_analysis", self._initial_analysis_node)
        workflow.add_node("decide_tools", self._decide_tools_node)
        workflow.add_node("execute_environment", self._execute_environment_node)
        workflow.add_node("execute_web_search", self._execute_web_search_node)
        workflow.add_node("execute_knowledge", self._execute_knowledge_node)
        workflow.add_node("evaluate_completeness", self._evaluate_completeness_node)
        workflow.add_node("final_compilation", self._final_compilation_node)
        workflow.add_node("no_tools_needed", self._no_tools_needed_node)
        
        # ì—£ì§€ ë° ì¡°ê±´ë¶€ ë¼ìš°íŒ… ì¶”ê°€
        workflow.set_entry_point("initial_analysis")
        
        # initial_analysisì—ì„œ ì¡°ê±´ë¶€ ë¶„ê¸°
        workflow.add_conditional_edges(
            "initial_analysis",
            self._should_use_tools,
            {
                "use_tools": "decide_tools",
                "no_tools": "no_tools_needed"
            }
        )
        
        # decide_toolsì—ì„œ í•„ìš”í•œ ë„êµ¬ë³„ ë¶„ê¸°
        workflow.add_conditional_edges(
            "decide_tools", 
            self._route_to_tools,
            {
                "environment": "execute_environment",
                "web_search": "execute_web_search", 
                "knowledge": "execute_knowledge",
                "evaluate": "evaluate_completeness"
            }
        )
        
        # ê° ë„êµ¬ ì‹¤í–‰ í›„ ì™„ì„±ë„ í‰ê°€ë¡œ
        workflow.add_edge("execute_environment", "evaluate_completeness")
        workflow.add_edge("execute_web_search", "evaluate_completeness")
        workflow.add_edge("execute_knowledge", "evaluate_completeness")
        
        # ì™„ì„±ë„ í‰ê°€ì—ì„œ ì¡°ê±´ë¶€ ë¶„ê¸° (ë£¨í”„ í¬í•¨)
        workflow.add_conditional_edges(
            "evaluate_completeness",
            self._check_if_complete,
            {
                "complete": "final_compilation",
                "need_more": "decide_tools",  # ë‹¤ì‹œ ë„êµ¬ ì„ íƒìœ¼ë¡œ (ë£¨í”„)
                "max_iterations": "final_compilation"
            }
        )
        
        # ìµœì¢… ë…¸ë“œë“¤
        workflow.add_edge("final_compilation", END)
        workflow.add_edge("no_tools_needed", END)
        
        return workflow.compile()
    
    def _initial_analysis_node(self, state: OrchestratorState) -> OrchestratorState:
        """ì´ˆê¸° ì§ˆì˜ ë¶„ì„"""
        query = state["query"]
        conversation_history = state.get("conversation_history", [])
        
        # ìµœê·¼ ëŒ€í™” ë‚´ìš© (ìµœëŒ€ 10ê°œ)
        recent_history = conversation_history[-10:] if conversation_history else []
        history_context = ""
        if recent_history:
            history_context = "\n\nìµœê·¼ ëŒ€í™” ë‚´ìš©:\n"
            for msg in recent_history:
                role = "ì‚¬ìš©ì" if msg["role"] == "user" else "ì‹ë¬¼ì¹œêµ¬"
                history_context += f"{role}: {msg['content']}\n"
        
        analysis_prompt = f"""
        ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë„êµ¬ê°€ í•„ìš”í•œì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

        í˜„ì¬ ì§ˆë¬¸: "{query}"
        {history_context}

        ë¶„ì„í•´ì•¼ í•  ê²ƒ:
        1. ì´ ì§ˆë¬¸ì´ ì‹ë¬¼ ê´€ë ¨ ì •ë³´ë¥¼ í•„ìš”ë¡œ í•˜ëŠ”ê°€?
        2. ë‹¨ìˆœí•œ ì¸ì‚¬ë‚˜ ëŒ€í™”ì¸ê°€?
        3. êµ¬ì²´ì ì¸ ë°ì´í„°ë‚˜ ì •ë³´ê°€ í•„ìš”í•œê°€?
        4. ì´ì „ ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í–ˆì„ ë•Œ ì–´ë–¤ ì •ë³´ê°€ í•„ìš”í•œê°€?

        ì‘ë‹µ í˜•ì‹ (JSON):
        {{
            "needs_tools": true/false,
            "reasoning": "íŒë‹¨ ì´ìœ ",
            "complexity": "simple|medium|complex"
        }}
        """
        
        try:
            response = self.llm.invoke([SystemMessage(content=analysis_prompt)])
            analysis_result = json.loads(response.content)
        except:
            analysis_result = {"needs_tools": True, "reasoning": "ë¶„ì„ ì‹¤íŒ¨ë¡œ ì•ˆì „í•˜ê²Œ ë„êµ¬ ì‚¬ìš©", "complexity": "medium"}
        
        state["analysis_result"] = analysis_result
        state["iteration_count"] = 0
        state["is_complete"] = False
        
        return state
    
    def _decide_tools_node(self, state: OrchestratorState) -> OrchestratorState:
        """AIê°€ ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í• ì§€ ê²°ì •"""
        query = state["query"]
        current_results = state.get("tool_results", {})
        iteration = state["iteration_count"]
        
        decision_prompt = f"""
        ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì¤‘ ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í• ì§€ ê²°ì •í•´ì£¼ì„¸ìš”.

        ì‚¬ìš©ì ì§ˆë¬¸: "{query}"
        í˜„ì¬ ë°˜ë³µ íšŸìˆ˜: {iteration}
        ì´ë¯¸ ìˆ˜ì§‘ëœ ì •ë³´: {list(current_results.keys())}

        ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:
        1. environment: {self.tool_descriptions["environment"]}
        2. web_search: {self.tool_descriptions["web_search"]}
           - AIê°€ ìë™ìœ¼ë¡œ ì ì ˆí•œ Exa Search ë„êµ¬ë¥¼ ì„ íƒ (web_search_exa, research_paper_search_exa, wikipedia_search_exa ë“±)
        3. knowledge: {self.tool_descriptions["knowledge"]}

        ê²°ì • ê¸°ì¤€:
        - ì•„ì§ ìˆ˜ì§‘í•˜ì§€ ì•Šì€ ì •ë³´ê°€ ìˆë‹¤ë©´ í•´ë‹¹ ë„êµ¬ ì„ íƒ
        - ì´ë¯¸ ì¶©ë¶„í•œ ì •ë³´ê°€ ìˆë‹¤ë©´ "evaluate"
        - í™˜ê²½/ìƒíƒœ ì§ˆë¬¸ â†’ environment
        - íŠ¸ë Œë“œ/ìµœì‹  ì •ë³´/ì—°êµ¬ ìë£Œ â†’ web_search (AIê°€ ì ì ˆí•œ Exa Search ë„êµ¬ ìë™ ì„ íƒ)
        - ì „ë¬¸ ì§€ì‹/ê´€ë¦¬ë²• â†’ knowledge

        ì‘ë‹µ í˜•ì‹ (JSON):
        {{
            "next_tool": "environment|web_search|knowledge|evaluate",
            "reasoning": "ì„ íƒ ì´ìœ "
        }}
        """
        
        try:
            response = self.llm.invoke([SystemMessage(content=decision_prompt)])
            decision = json.loads(response.content)
            state["next_action"] = decision.get("next_tool", "evaluate")
            state["reasoning"] = decision.get("reasoning", "")
        except:
            state["next_action"] = "evaluate"
            state["reasoning"] = "ê²°ì • ì‹¤íŒ¨ë¡œ í‰ê°€ ë‹¨ê³„ë¡œ"
        
        return state
    
    def _execute_environment_node(self, state: OrchestratorState) -> OrchestratorState:
        """í™˜ê²½ ë°ì´í„° ë„êµ¬ ì‹¤í–‰ (API ë²„ì „)"""
        try:
            # APIë¡œ ë°›ì€ í™˜ê²½ ë°ì´í„°ë¥¼ ë¶„ì„
            if hasattr(self, 'current_env_data') and self.current_env_data:
                # í™˜ê²½ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° ë¶„ì„ ìˆ˜í–‰
                env_result = self.env_analyzer.analyze_plant_health_from_api(self.current_env_data)
            else:
                # í™˜ê²½ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë©”ì‹œì§€
                env_result = "í™˜ê²½ ë°ì´í„° ë¶„ì„ì„ ìœ„í•´ì„œëŠ” í˜„ì¬ ì„¼ì„œ ë°ì´í„°(ì˜¨ë„, ìŠµë„, ê´‘ë„, í† ì–‘ìˆ˜ë¶„)ê°€ í•„ìš”í•©ë‹ˆë‹¤. APIë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ì „ë‹¬í•´ì£¼ì„¸ìš”."
            
            if "tool_results" not in state:
                state["tool_results"] = {}
            state["tool_results"]["environment"] = env_result
            state["reasoning"] += " | í™˜ê²½ ë°ì´í„° ë¶„ì„ ì™„ë£Œ"
        except Exception as e:
            if "tool_results" not in state:
                state["tool_results"] = {}
            state["tool_results"]["environment_error"] = str(e)
            state["reasoning"] += f" | í™˜ê²½ ë°ì´í„° ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        
        state["iteration_count"] += 1
        return state
    
    def _execute_web_search_node(self, state: OrchestratorState) -> OrchestratorState:
        """Exa Search MCP ë„êµ¬ ì‹¤í–‰ - AIê°€ ì ì ˆí•œ ê²€ìƒ‰ ë„êµ¬ë¥¼ ì„ íƒ"""
        try:
            # AI Agentê°€ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•´ì„œ ì ì ˆí•œ Exa Search ë„êµ¬ë¥¼ ì„ íƒí•˜ì—¬ ê²€ìƒ‰
            search_results = self.web_search.search_plant_info(state["query"])
            
            # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ ìƒì„±
            web_result = {
                'query': state["query"],
                'total_results': len(search_results),
                'summary': search_results[0]['content'][:300] + "..." if search_results and search_results[0]['content'] else "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ",
                'sources': [r.get('source', 'Unknown') for r in search_results],
                'used_tools': search_results[0].get('used_tools', []) if search_results else [],
                'timestamp': 'Just now',
                'search_engine': 'Exa Search MCP'
            }
            
            if "tool_results" not in state:
                state["tool_results"] = {}
            state["tool_results"]["web_search"] = web_result
            
            # ì‚¬ìš©ëœ Exa Search ë„êµ¬ë“¤ ë¡œê¹…
            used_tools = web_result['used_tools']
            if used_tools:
                state["reasoning"] += f" | Exa Search ì™„ë£Œ (ì‚¬ìš© ë„êµ¬: {', '.join(used_tools)})"
            else:
                state["reasoning"] += " | Exa Search ì™„ë£Œ"
                
        except Exception as e:
            # ì—ëŸ¬ ë°œìƒ ì‹œ fallback ê²°ê³¼ ì œê³µ
            error_result = {
                'query': state["query"],
                'total_results': 0,
                'summary': f"Exa Search MCP ì—°ê²° ì‹¤íŒ¨: {str(e)}",
                'sources': ['Fallback'],
                'used_tools': ['fallback'],
                'timestamp': 'Just now',
                'search_engine': 'Exa Search MCP (Fallback)'
            }
            
            if "tool_results" not in state:
                state["tool_results"] = {}
            state["tool_results"]["web_search"] = error_result
            state["reasoning"] += f" | Exa Search ì‹¤íŒ¨ (Fallback ì‚¬ìš©): {str(e)}"
        
        state["iteration_count"] += 1
        return state
    
    def _execute_knowledge_node(self, state: OrchestratorState) -> OrchestratorState:
        """ì§€ì‹ ê²€ìƒ‰ ë„êµ¬ ì‹¤í–‰"""
        try:
            knowledge_result = self.rag_system.get_knowledge_summary(state["query"])
            if "tool_results" not in state:
                state["tool_results"] = {}
            state["tool_results"]["knowledge"] = knowledge_result
            state["reasoning"] += " | ì§€ì‹ ê²€ìƒ‰ ì™„ë£Œ"
        except Exception as e:
            state["tool_results"]["knowledge_error"] = str(e)
        
        state["iteration_count"] += 1
        return state
    
    def _evaluate_completeness_node(self, state: OrchestratorState) -> OrchestratorState:
        """AIê°€ ìˆ˜ì§‘ëœ ì •ë³´ê°€ ì¶©ë¶„í•œì§€ í‰ê°€"""
        query = state["query"]
        current_results = state.get("tool_results", {})
        iteration = state["iteration_count"]
        
        evaluation_prompt = f"""
        ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ìˆ˜ì§‘ëœ ì •ë³´ê°€ ì¶©ë¶„í•œì§€ í‰ê°€í•´ì£¼ì„¸ìš”.

        ì‚¬ìš©ì ì§ˆë¬¸: "{query}"
        ìˆ˜ì§‘ëœ ì •ë³´: {list(current_results.keys())}
        í˜„ì¬ ë°˜ë³µ íšŸìˆ˜: {iteration}

        í‰ê°€ ê¸°ì¤€:
        1. ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•œ í•µì‹¬ ì •ë³´ê°€ ëª¨ë‘ ìˆëŠ”ê°€?
        2. ì¶”ê°€ë¡œ í•„ìš”í•œ ì •ë³´ê°€ ìˆëŠ”ê°€?
        3. ì´ë¯¸ 3ë²ˆ ì´ìƒ ë°˜ë³µí–ˆë‹¤ë©´ ì¶©ë¶„í•˜ë‹¤ê³  íŒë‹¨

        ì‘ë‹µ í˜•ì‹ (JSON):
        {{
            "is_complete": true/false,
            "missing_info": "ë¶€ì¡±í•œ ì •ë³´ ì„¤ëª…",
            "confidence": 0.8
        }}
        """
        
        try:
            response = self.llm.invoke([SystemMessage(content=evaluation_prompt)])
            evaluation = json.loads(response.content)
            state["is_complete"] = evaluation.get("is_complete", True)
            state["reasoning"] += f" | ì™„ì„±ë„ í‰ê°€: {evaluation.get('confidence', 0.5)}"
        except:
            state["is_complete"] = True  # í‰ê°€ ì‹¤íŒ¨ ì‹œ ì™„ë£Œë¡œ ì²˜ë¦¬
        
        return state
    
    def _final_compilation_node(self, state: OrchestratorState) -> OrchestratorState:
        """ìµœì¢… ê²°ê³¼ ì»´íŒŒì¼"""
        state["is_complete"] = True
        state["reasoning"] += " | ìµœì¢… ì»´íŒŒì¼ ì™„ë£Œ"
        return state
    
    def _no_tools_needed_node(self, state: OrchestratorState) -> OrchestratorState:
        """ë„êµ¬ ì—†ì´ ì²˜ë¦¬ ê°€ëŠ¥í•œ ê²½ìš°"""
        state["is_complete"] = True
        state["tool_results"] = {}
        state["reasoning"] = "ë„êµ¬ ì—†ì´ ì¼ë°˜ ëŒ€í™”ë¡œ ì²˜ë¦¬"
        return state
    
    # ì¡°ê±´ë¶€ ë¼ìš°íŒ… í•¨ìˆ˜ë“¤
    def _should_use_tools(self, state: OrchestratorState) -> Literal["use_tools", "no_tools"]:
        """ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ ê²°ì •"""
        analysis = state.get("analysis_result", {})
        return "use_tools" if analysis.get("needs_tools", True) else "no_tools"
    
    def _route_to_tools(self, state: OrchestratorState) -> Literal["environment", "web_search", "knowledge", "evaluate"]:
        """ë‹¤ìŒ ë„êµ¬ ë¼ìš°íŒ…"""
        return state.get("next_action", "evaluate")
    
    def _check_if_complete(self, state: OrchestratorState) -> Literal["complete", "need_more", "max_iterations"]:
        """ì™„ì„±ë„ ì²´í¬"""
        if state["iteration_count"] >= 3:  # ìµœëŒ€ 3ë²ˆ ë°˜ë³µ
            return "max_iterations"
        elif state.get("is_complete", False):
            return "complete"
        else:
            return "need_more"
    
    def analyze_and_execute(self, query: str, conversation_history: List[Dict] = None, env_data: Optional[Dict] = None) -> Dict:
        """ë©”ì¸ ì¸í„°í˜ì´ìŠ¤: ë³µì¡í•œ LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        try:
            # í™˜ê²½ ë°ì´í„° ì„¤ì • (APIì—ì„œ ë°›ì€ ë°ì´í„°)
            if env_data:
                self.current_env_data = env_data
            
            # ì´ˆê¸° ìƒíƒœ ìƒì„±
            initial_state = OrchestratorState(
                messages=[HumanMessage(content=query)],
                query=query,
                conversation_history=conversation_history or [],
                analysis_result={},
                tools_to_use=[],
                tool_results={},
                reasoning="",
                iteration_count=0,
                is_complete=False,
                next_action=""
            )
            
            # ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            result = self.workflow.invoke(initial_state)
            
            # ê²°ê³¼ ì •ë¦¬
            tools_used = list(result.get("tool_results", {}).keys())
            
            return {
                "query_analysis": {
                    "query_type": result["analysis_result"].get("complexity", "unknown"),
                    "tools_needed": tools_used,
                    "reasoning": result["reasoning"],
                    "confidence": 0.9,
                    "iterations": result["iteration_count"]
                },
                "tool_results": result.get("tool_results", {}),
                "reasoning": result["reasoning"],
                "workflow_path": f"ë°˜ë³µ {result['iteration_count']}íšŒ, ì‚¬ìš© ë„êµ¬: {tools_used}",
                "success": True
            }
            
        except Exception as e:
            return {
                "query_analysis": {"query_type": "error", "tools_needed": [], "reasoning": f"ì˜¤ë¥˜: {str(e)}", "confidence": 0.0},
                "tool_results": {"error": str(e)},
                "reasoning": f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}",
                "workflow_path": "ì˜¤ë¥˜ë¡œ ì¸í•œ ì¤‘ë‹¨",
                "success": False
            }
    
    def get_available_tools(self) -> Dict:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ë° ì„¤ëª… ë°˜í™˜"""
        return self.tool_descriptions


# í…ŒìŠ¤íŠ¸ìš© ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    orchestrator = PlantOrchestrator()
    
    print("=== ë³µì¡í•œ LangGraph ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ===")
    
    # í…ŒìŠ¤íŠ¸ ì§ˆì˜ë“¤
    test_queries = [
        "ë‚´ ìƒíƒœ ì–´ë•Œ?",
        "ìš”ì¦˜ ì‹ë¬¼ íŠ¸ë Œë“œëŠ”?", 
        "ëª¬ìŠ¤í…Œë¼ í‚¤ìš°ëŠ” ë²•?",
        "ê±´ê°•í•˜ê²Œ ì˜ ìë¼ê³  ìˆì–´? ìš”ì¦˜ ìœ í–‰í•˜ëŠ” ê´€ë¦¬ë²•ë„ ì•Œë ¤ì¤˜",
        "ì•ˆë…•!"
    ]
    
    for query in test_queries:
        print(f"\n{'='*60}")
        print(f"ğŸ” ì§ˆì˜: {query}")
        
        result = orchestrator.analyze_and_execute(query)
        
        print(f"ğŸ§  AI ë¶„ì„: {result['query_analysis']['query_type']}")
        print(f"ğŸ”§ ì‚¬ìš©ëœ ë„êµ¬: {result['query_analysis']['tools_needed']}")
        print(f"ğŸ›¤ï¸ ì›Œí¬í”Œë¡œìš° ê²½ë¡œ: {result['workflow_path']}")
        print(f"ğŸ’­ AI ì¶”ë¡ : {result['reasoning']}")
        print(f"ğŸ“Š ì‹ ë¢°ë„: {result['query_analysis'].get('confidence', 'N/A')}")
        
        if result['tool_results']:
            print(f"ğŸ“¦ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼: {list(result['tool_results'].keys())}")
            
        print(f"âœ… ì„±ê³µ: {result['success']}")